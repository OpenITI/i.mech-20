ms81	 المصفوفة، وعلى حقيقة المزاعم حولها. يكمن الفخ ها هنا في المساواة بين الوجود والواقع؛ أي الزعم بأن عالم المصفوفة واقعي مثله مثل عالم زيون؛ كلا العالمين موجودان في النهاية، ونحن لا نصف شيئا بأنه واقع إلا إذا كان موجودا. التفسير الأفلاطوني يقاوم الوقوع في هذا الفخ؛ إذ يربط مفهوم الواقع بما هو أكثر من مجرد الوجود.(@)(@)(@@) إحدى طرق التعبير عن النقطة الأساسية التي يطرحها التفسير الأفلاطوني هي كالتالي: العالم خارج المصفوفة «واقعي أكثر» من العالم داخلها. للواقعية درجات، وهي تختلف عن الوجود. الأشياء إما توجد أو لا توجد. على العكس من ذلك قد تكون الأشياء أكثر أو أقل واقعية. الظلال على حائط كهف أفلاطون أقل واقعية من الأجسام التي تنعكس عنها. الملعقة داخل المصفوفة أقل واقعية من الملعقة في مدينة زيون. ماذا يحدد كون أحد الأشياء أكثر واقعية من الآخر؟ في كل من كهف أفلاطون وسيناريو المصفوفة، تتعلق المسألة بالأصالة. ملعقة زيون هي شيء أكثر أصالة لأن ملعقة المصفوفة هي نسخة منها. ملعقة زيون هي الملعقة الأصلية الحقيقية، بينما ملعقة المصفوفة تقليد مزيف إلى حد ما. يبدو تفسير مستويات الواقعية من منظور الأصالة منطقيا عند تطبيقه على نظرية الأشكال التي وضعها أفلاطون، وينجح كذلك مع سيناريو المصفوفة؛ لكنه لا يثير الاهتمام كثيرا من المنظور الفلسفي إلا إذا اعتنقت نظرية الأشكال أو اعتبرت فيلم «المصفوفة» فيلما وثائقيا.(@)(@)(@@) هل يوجد سبيل أكثر إثارة للاهتمام من الناحية الفلسفية لتعريف درجات الواقعية، سبيل يقدر قصة كهف أفلاطون وحجيرة نيو حق قدرهما لكن لا يساوي بين الواقعية والأصالة؟ ربما يوجد سبيل كهذا. قد نحاول تعريف درجات الواقعية كالتالي: «أ» واقعي أكثر من «ب» إذا كانت النظرية التي تفترض «أ» تطرح رؤية أدق وأكثر اكتمالا للعالم من النظرية التي تفترض «ب».(@)(@)(@@) إن منظور المصفوفة للأشياء ليس زائفا بقدر ما هو أجوف. وعلم الوجود لدى فيلسوف المصفوفة ليس خاطئا على نحو جذري بقدر ما هو سطحي. فعناصر علم الوجود الذي يطرحه فيلسوف المصفوفة ستكون أقل واقعية عن 
ms82	 عناصر علم الوجود الذي يطرحه المعماري على سبيل المثال؛ ففيلسوف المصفوفة أقل اتصالا بالواقع. هو لا يتصل بأجزاء أقل من العالم، بل هو أقل اتصالا بالعالم كله.(@)(@)(@@) الدرس الأهم الذي علينا تعلمه من التفسير الأفلاطوني لا يرجع بالضرورة إلى أفلاطون أو حتى إلى نيو. فكما لاحظنا، كان أفلاطون متفائلا تفاؤلا عظيما حيال قدرة التأمل الفلسفي على تحريرنا من كهف الجهل وكشف الحقيقة المطلقة لنا. أما «ثلاثية المصفوفة» فتجعلنا نتوقف ونعيد النظر في ذلك التفاؤل. على أي أساس يمكننا الوثوق في أن تلك الحقيقية المطلقة هي شيء في وسعنا معرفته؟ هل أفضل ما أنتجناه من علم يمنحنا صورة كاملة ودقيقة لطبيعة الأشياء، أم لا يمنح سوى صورة سطحية وناقصة لبعض جوانب العالم؟ (لقد ثبت خطأ نظريات علمية ماضية، فلماذا نعتقد أن النظريات الحالية ستسفر عن نتائج أفضل؟ ولماذا نعتقد أن أي نظرية مستقبلية ستحقق نتائج أفضل؟) ربما كان العالم أعمق وأكثر غموضا بكثير مما يبدو، ربما يكون الموقف الأكثر عقلانية حيال معرفة الحقيقة المطلقة موقفا تشككيا؛ فنحن لن نعرف أننا نملك هذه المعرفة حتى لو كانت لدينا.(@)(@)(@@) نضيف ها هنا فكرة أخرى إلى هذه الأفكار. إن قدرتنا على ابتداع المفاهيم وصياغة النظريات وملاحظة الظواهر، نستمدها من الأداء الوظيفي لأدمغتنا، الذي تطور لأداء بعض المهام البسيطة للغاية؛ كتتبع من يمتون لنا بصلة، وتحديد أماكن الطعام، ومعرفة من قد نستطيع ممارسة الجنس معه، وغيرها من المهام. هل من المنطقي افتراض أن دماغا تطورت للتعامل مع مشكلات وفرص الرئيسيات الاجتماعية تتمتع بالقدرات المناسبة لفهم طبيعة الحقيقة المطلقة؟ ماذا يدفعنا للتفكير في هذا الافتراض؟ إن كوننا عالقين داخل مصفوفة أمر مستحيل تقريبا. فهل من المنطقي على الإطلاق افتراض أننا عالقون في مسرحية تتمحور حبكتها في المقام الأول حولنا؟ رغم ذلك ربما نكون بالفعل عالقين داخل شيء ما، لا نملك أدنى فكرة عن طبيعته. وطبيعته لا يمكننا معرفة أي شيء عنها على الإطلاق. ربما كان العالم منطقيا، لكنه لن يبدو منطقيا لنا أبدا. لخص عالم الأحياء 
ms83	 العظيم جيه بي إس هالدان (1930: 286) هذه الفكرة تلخيصا دقيقا حقا حيث قال:(@)(@)(@@) لا شك لدي في أن واقع المستقبل سيكون أكثر إدهاشا بمراحل من أي شيء يمكنني تخيله. لكنني أشك حاليا في أن الكون ليس أغرب مما نفترض فحسب، بل أغرب مما نستطيع افتراضه.(@)(@)(@@) أسئلة(@)(@)(@@) هل يهمك ما إذا كانت تجاربك حقيقية أم لا، وإذا كنت مهتما بأمر كهذا، فما السبب؟(@)(@)(@@) هل توجد «عوالم واقعية» أخرى ربما تكون أفضل من واقعك، لأي عدد من الأسباب؟ هل يعتبر اختيار هذا البديل رغم ذلك تصرفا غير عقلاني؟(@)(@)(@@) قدمنا في هذا الفصل مصطلحي «الإقصائية» و«الاختزالية». يتبنى التفسير الديكارتي وجهة النظر الإقصائية حيال الأشياء داخل المصفوفة، بينما يتبنى التفسير الواقعي وجهة النظر الاختزالية في التعامل معها. ما رأي التفسير الأفلاطوني في وجهتي النظر هاتين؟(@)(@)(@@) ذكرنا في هذا الفصل أن «مفتاح فهم التفكير داخل المصفوفة هو تأمل مضمون المعتقدات. ما الذي تتمركز حوله معتقدات المرء؟ كيف تكتسب المعتقدات مضمونها؟ من أين يأتي هذا المضمون؟» لماذا تعتبر هذه النقلة في غاية الأهمية؟ كيف تثبت أن المعتقدات العادية لدى مواطني المصفوفة هي معتقدات صحيحة؟ هل تثبت أنها صحيحة؟ ما الافتراضات التي يطرحها التفسير الديكارتي وتؤدي إلى الاستنتاج المعاكس؟(@)(@)(@@) فضاء المصفوفة لا يشبه الفضاء. وأشياء المصفوفة ليست كالأشياء؛ لأنها لا تتمتع بخصائص تشبه خصائص الفضاء، ولأنها لا تتمتع بوجود منفصل. عندما يفكر مواطنو المصفوفة في حمل شيء ما، ملعقة مثلا، فهم يستنتجون خطأ أنه شيء. هم يعتقدون أنه يوجد في فضاء (في حين أنه لا يوجد). يعتقدون أنه يتمتع بخصائص مكانية (لا يتمتع بها). هم يعتقدون أن له وزنا (ليس له وزن، إنه مجرد هيكل معلوماتي، يوجد في أجزاء متنوعة من الكمبيوتر في أوقات مختلفة؛ إنه ليس حزمة منفصلة من شرائح السيليكون على سبيل المثال؛ ولذلك لا وزن له). إلى أي مدى تبدو هذه الحجة منطقية؟ ربما يكون التفسير الديكارتي للمصفوفة صحيحا رغم كل شيء؟(@)(@)(@@) في هذا الفصل قارنا بين طريقتين للزعم القائل بأن للواقعية درجات، فتوجد 
ms84	 الواقعية الناتجة عن الأصالة، والواقعية المعتمدة على النظرية (حيث يعتبر الشيء أكثر واقعية من شيء آخر إذا كانت النظرية التي تقترحه أدق وأكثر اكتمالا من النظرية التي تقترح الشيء الآخر؛ ومن ثم الكأس أقل واقعية من الإلكترون). هل يجسد أي من هاتين الرؤيتين صورة مقبولة بديهيا للكيفية التي يصبح بها شيء ما أكثر واقعية من شيء آخر؟ هل للواقعية درجات؟ أم هل الواقعية لا تختلف في شيء عن الوجود؟(@)(@)(@@) مع نهاية الفصل، ألمحنا إلى حجة تشككية حول الحقيقة النهائية. ما مدى معقولية هذه الحجة؟ (تزعم الحجة باختصار أنه من غير المحتمل على الإطلاق (بل يصل بالتأكيد إلى حد الإعجاز) أن تملك قدراتنا الإدراكية المحدودة التي تطورت عرضا القدرة على استيعاب طبيعة الحقيقة المطلقة.)(@)(@)(@@) نحن لا نختبر الأشياء ولا ندركها إلا عبر أنظمتنا المعرفية والإدراكية الحسية. لا يمكننا قط رؤية الأشياء أو فهمها كما هي «في حد ذاتها»؛ لذا فالحقيقة المطلقة أمر من المستحيل معرفته أو التفكير فيه على نحو غير مشوه تماما. ما صلة هذه الحجة بالحجة التشككية حول الحقيقة المطلقة التي قدمناها في هذا الفصل؟ أهي حجة منطقية؟(@)(@)(@)(@)(@@) | هوامش(@)(@)(@)(@)(@)(@)(@)(@@) الفصل الخامس(@)(@)(@)(@)(@@) | العقل هو الأساس: «ذكاء اصطناعي» ومشاعر الحب لدى الروبوت(@)(@)(@)(@)(@)(@@) مقدمة(@)(@)(@@) ديفيد يبلغ من العمر أحد عشر عاما، يزن ستين رطلا، ويبلغ طوله أربعة أقدام وست بوصات. شعره بني. حب ديفيد حقيقي، لكن ديفيد ليس حقيقيا.(@)(@)(@@) كان هذا الشعار الدعائي لفيلم «ذكاء اصطناعي» (2001). سوف نستخدم نموذج ديفيد ونحن نبحث فلسفة الذكاء الاصطناعي. نناقش ها هنا زعما طموحا إلى حد استثنائي وهو ما إذا كان ممكنا (ربما في المستقبل القريب) خلق كائنات ذكية واعية، كائنات لا تكتفي بحل المعضلات فحسب بل تدرك ما تقوم بحله ولماذا، كائنات تفهم ما تتحدث عنه وتدرك ماهيتها، كائنات تملك معتقدات ورغبات حقيقية وتشعر بأحاسيس وتشعر بمشاعر حقيقية. يتمحور السؤال الفلسفي الرئيسي ها هنا حول فكرة الاحتمالية: هل هذا محتمل من الأساس؟(@)(@)(@@) 1(@)(@)(@@) في هذا الفصل لا يلقي الفيلم الذي وقع عليه اختيارنا ضوءا كبيرا على 
ms85	 هذه القضية. عوضا عن ذلك أعدت مناقشاتنا الفلسفية بهدف توضيح الفيلم والاحتمالية التي يجسدها. السؤال المحوري هو ما إذا كانت المخلوقات التي تتمتع بذكاء اصطناعي لديها حياة داخلية، والسبب الرئيسي الذي يعوق أفلاما مثل «ذكاء اصطناعي» عن مساعدتنا حقا في محاولة الإجابة عن هذا السؤال هو أنه من السهل جدا على تلك الأفلام التهرب من السؤال. غالبا ما تعج أفلام الخيال العلمي بروبوتات واعية، لكن هذا لا يساعد على الإجابة عن سؤال يتعلق بما إذا كان ذلك ممكنا حقا. الأفلام لا توضح لنا الحياة الداخلية لشخصياتها، سواء البشر أو الروبوتات، بل تتركنا لاستنتاج هذه الحياة الداخلية، وهي في ذلك لا تختلف كثيرا عما يحدث في الحياة العادية.(@)(@)(@@) 2(@)(@)(@@) عندما يقدم لنا أحد الأفلام شخصية أعدت لأداء دور روبوت واع ضمن أحداث الفيلم، لا بد أن نستنتج كونه واعيا من طريقة تصرفه. لكن لدى صناع الأفلام طرق كثيرة لضمان توصلنا إلى هذا الاستنتاج دون الخوض في مناقشة حول ما إذا كان الروبوت واعيا حقا أم لا.(@)(@)(@@) 3(@)(@)(@@) نحن نميل إلى عزو الوعي إلى الروبوت ما دام سلوكه يبدو ذكيا وصريحا وذا معنى وما دام الروبوت يعامل في الفيلم كما لو كان واعيا (على سبيل المثال الروبوت هال في فيلم «2001: ملحمة الفضاء» (2001: سبايس أوديسي) (1968))؛ ومن ثم ننقاد بسهولة إلى تبني ما يطلق عليه الفيلسوف دانيال دانيت (1989) «الموقف القصدي» حيال تلك التجسيدات. يسهل صناع الأفلام هذه المهمة عبر إعطاء الروبوت شكلا بشريا (مثل الروبوت سوني في فيلم «أنا روبوت» (آي روبوت) (2004))، ويجعلونها في غاية السهولة حقا عندما يسندون دور الروبوت إلى شخص حقيقي (مثل روبن وليامز في فيلم «رجل المائتي سنة» (بايسينتينيال مان) (1999)). وفي «ذكاء اصطناعي» تمكن سبيلبيرج من تحقيق التأثير الذي أراده عبر إسناد دور الروبوت الصبي إلى صبي حقيقي وهو هالي جويل أوزمنت (حقا قد ولت أيام الروبوت المعدني أرتو دي تو في فيلم «حرب النجوم»).(@)(@)(@@) يقدم الفيلم شخصية ديفيد في دور روبوت واع تماما، ويعلن عن هذا بوضوح؛ إذ تصرح شخصية البروفيسور 
ms86	 هوبي في بداية الفيلم (الدقيقة 6) أن ديفيد هو نوع جديد من الروبوتات، نوع مصمم بحيث يتمتع بحياة داخلية ؛ أي إنه يشعر ويتخيل ويتوق ويحلم. هل كان هوبي محقا في وصفه للروبوت؟ هذا هو السؤال الذي سننشغل به على مدار هذا الفصل. لا «يبدو» ديفيد واعيا فحسب، بل يتمتع بوعي عميق ومتكامل؛ فلا يبدو مستوعبا لما يحيط به فقط، بل يجاهد لإرضاء رغباته، ويشعر بمشاعر على ما يبدو. يبدو أنه يشعر بحب الصبي لأمه (ليست أمه الحقيقية بالطبع بل مونيكا؛ الشخصية التي يعتبرها أمه). ينطلق ديفيد في مسعاه للتحول إلى صبي حقيقي (أي صبي عضوي لا آلي) من أجل أن يستعيد حب مونيكا. ويخبرنا الشعار الدعائي أن حبه حقيقي، لكن كيف يتأتى هذا؟ ما الذي يحتاجه الحب كي يصبح حقيقيا؟ قبل أن نشق طريقنا عبر فلسفة الذكاء الاصطناعي، يجدر بنا التوقف للحظة وتأمل هذا السؤال. ما الذي يجعل الحب حبا حقيقيا؟ تعتمد الإجابة بالطبع على ما نعنيه بالحب.(@)(@)(@@) لا يحب الطفل والديه مثلما قد يحب شخص ناضج شخصا آخر ناضجا، أو مثلما قد يحب شخص ناضج طفلا (على الرغم من أن التشابه بين الحالتين جدير بالملاحظة). حب الطفل هو شكل من الاعتماد العاطفي في المقام الأول - شكل خاص مفعم بالحيوية، لكنه في النهاية يظل شكلا من الاعتماد. يتألف حب ديفيد من ميل إلى إبداء العاطفة، مرارا وتكرارا، إلى جانب نوع من الحاجة الملحة، الحاجة إلى عاطفة مونيكا وقربها واهتمامها وقبولها وحضورها. لا يحتاج ديفيد أن ترعاه مونيكا بطريقة عملية (فهو روبوت، وهي ليست مسئولة عن صيانته). رغم ذلك هو يحتاج أن «تهتم» به. لا يحتاج ديفيد أن تكون مونيكا سعيدة فقط، بل يحتاج أن تكون سعيدة معه؛ أي راضية عنه وسعيدة في صحبته أيضا. في بلاد الإغريق قديما، ميز الفلاسفة بين ثلاثة أنواع من الحب: الحب الشهواني، والمحبة، والألفة. يعتمد الحب الشهواني - وهو عادة، وإن لم يكن بالضرورة، الحب الشبقي أو الجنسي - على رغبة وحاجة عاطفية (الحاجة العاطفية هي رغبة قد 
ms87	 تؤدي حال عدم إرضائها إلى ضرر عاطفي كبير). أما المحبة الخالصة فهي نوع من الحب المنزه من الأغراض ، الحب الذي يمنح المتلقي قيمة بدلا من أن يستمد منه قيمة، ونموذجه هو الحب الذي يقال أحيانا إن الله يشعر به تجاه البشر، وربما المخلوقات جميعها، أو حب الوالدين لطفلهما. وعلى النقيض تأتي الألفة، وهي مزيج من النوعين. عمليا هي نوع من المتعة المستمدة من الصداقة، ومن الاهتمام والاحترام اللذين يكنهما المرء لأصدقائه. في ضوء هذا التصنيف الثلاثي، يبدو أن حب الطفل لوالديه شكل من الحب الشهواني وحب ديفيد لمونيكا يجسد نموذجا معبرا عن ذلك. في هذا الصدد يبدو حب ديفيد لأمه لا يختلف كثيرا عما تتوقع من أي طفل طبيعي في الحادية عشرة من عمره. هو حنون وأناني ومتمركز حول ذاته وضعيف وحساس.(@)(@)(@@) ربما يبدو حب ديفيد لمونيكا أشبه كثيرا بحب الطفل، لكن هل يحبها حقا؟ يمنعنا سببان من الإجابة عن هذا السؤال بنعم. الأول أمر ذكرناه بالفعل؛ وهو أن ديفيد روبوت، ليس إنسانا من لحم ودم، هو إنسان آلي أو «ميكا» كما يطلقون عليه في الفيلم. هل يعتبر حب الإنسان الآلي تجربة عاطفية من الأساس؟ ربما كان حبه مجموعة من السلوكيات الروتينية التي تحاكي سلوك الحب ليس إلا. ربما هو شيء يشبه الحب كثيرا من الناحية الظاهرية، بينما لا يحوي في باطنه سوى فراغ. ربما كان الأمر كذلك. لكن يوجد سبب آخر يدفعنا إلى الشك في حقيقة أو أصالة حب ديفيد لمونيكا؛ لقد صمم ديفيد خصوصا كي يتعلق عاطفيا برمز أبوي. هل الحب الذي زرعه المصمم داخله هو حب حقيقي؟ هل هو حب «أصيل»؟ لقد صمم ديفيد كي يحب، بطريقته الطفولية بالغة الحدة، الشخص الذي يطبع بصمته عليه أولا. يقتضي نظام البصمة ترديد قائمة من كلمات مفتاحية بالترتيب مع لمس جسد ديفيد عند نقاط معينة. وهي عملية محددة سلفا إلى حد كبير، وآلية. رغم ذلك فإن مشهد طبع البصمة (الذي يبدأ في الدقيقة 21، الثانية 45 من الفيلم) مشهد رائع حقا بفضل 
ms88	 أداء أوزمنت البارع والبعيد عن المبالغة. قبل طبع البصمة، يؤدي أوزمنت دور ديفيد أداء متصلبا للغاية؛ إذ يجلس جامدا بينما تعلو وجهه ابتسامة ثابتة أشبه بابتسامة معتوه. يبدو وجه ديفيد عادة إما جامدا أو مشوها نتيجة لتعبير مبالغ فيه (كما هي الحال في مشهد الضحك في الدقيقة 19، الثانية 50 من الفيلم). لكن في مشهد طبع البصمة تلين ملامح ديفيد، وتبدو نظرته أكثر طبيعية، ويكتسب التعبير على وجهه سمتا أكثر بشرية. إن عملية طبع البصمة تحول الروبوت إلى شيء أشبه كثيرا بالإنسان. لكنها رغم ذلك ليست سوى عملية مثبتة داخله مسبقا. هي ليست تجربة اختار ديفيد خوضها أو شيئا حدث له في المسار الطبيعي للأحداث، بل هي عملية أعد لخوضها بطريقة محددة جدا. هل يعني هذا أن ارتباط ديفيد العاطفي بمونيكا ارتباط مصطنع ومزيف؟(@)(@)(@@) من الصعب تحديد مفهوم التجربة العاطفية «الأصيلة» بدقة، لكنه على ما يبدو يرتبط جزئيا بالسبب وراء التجربة العاطفية. على سبيل المثال، إذا جعلنا شخصا ما سعيدا عبر حقنه ب «عقار السعادة»، فإن سعادته لن تبدو سعادة أصيلة؛ فهي لم تحدث على النحو الصحيح، إذا جاز القول. وقد نزعم أن ذلك الشخص ليس سعيدا حقا، بل هو واقع تحت تأثير العقار فحسب. في حالة ديفيد، نجد أن حبه لمونيكا ناتج عن سبب غريب؛ ألا وهو عملية طبع البصمة المصممة لغرض محدد. ديفيد مصمم كي يشعر بالحب فور تفعيل برنامج البصمة؛ ألا يشبه ذلك حقنه ب «عقار الحب»؟ لكن من ناحية أخرى قد تكون فكرة أصالة حب الطفل لوالديه في حد ذاتها فكرة غير مناسبة. أليس نظام البصمة لدى ديفيد هو، من نواح عديدة، نسخة مبالغ فيها من المصدر الذي ينبع منه حب أي طفل؟ يشكل الأطفال ارتباطا عاطفيا بآبائهم، ويكونون اعتمادا عليهم، وهو سلوك يرجع في جزء منه على الأقل إلى الجينات. إذا اعتبرنا حب ديفيد غير أصيل لأنه مثبت مسبقا، فربما يصبح حب أي طفل لأمه غير أصيل كذلك لنفس السبب. نحن لا ننزع إلى الشك في حقيقة 
ms89	 أو أصالة حب الطفل لوالديه؛ لذا ربما لا ينبغي لنا التشكك في حب ديفيد لأن أصله يرجع إلى المصمم.(@)(@)(@@) إذا كان حب ديفيد غير حقيقي، فإن هذا لا يرجع إلى كونه مستمدا من برنامج البصمة المثبت مسبقا، بل يرجع لكون ديفيد روبوتا. ديفيد هو جهاز آلي، وربما تكون الأجهزة الآلية في الواقع مجرد مجموعة من الآلات الحاسوبية المعقدة. ربما هي عاجزة حقا عن فهم أي شيء أو الشعور بأي شيء. يطرح هذا الزعم اعتراضين أساسيين؛ الأول ينسب نوعا من القصور الإدراكي إلى الآلات الحاسوبية؛ فوظيفتها تقتصر على التعامل مع الأرقام والرموز ومعالجة المعلومات فحسب، وليس في وسعها أبدا إدراك ما تقوله أو تفعله. أما الاعتراض الثاني فينسب لها قصورا عاطفيا: الآلات الحاسوبية عاجزة عن الشعور بأي شيء، ربما تستطيع تنفيذ برامج عاطفية، فتتصرف كما لو كانت سعيدة أو مضطربة، لكنها من داخلها جامدة تماما، ولا تشعر بأي شيء. ما مدى منطقية هذين الاعتراضين؟ ما الأساس الذي يدعمهما؟ سوف نتوجه إلى ميدانين من ميادين الفلسفة؛ سعيا للإجابة عن تلك الأسئلة، وهما: فلسفة الذكاء الاصطناعي، وفلسفة العقل.(@)(@)(@@) هل في وسع الروبوت فهم أي شيء؟(@)(@)(@@) الذكاء الاصطناعي هو علم (وفن) صناعة آلات قادرة على أداء عمليات ذكية حقا. تستطيع أنظمة الذكاء الاصطناعي هزيمة أفضل لاعبي الشطرنج في العالم، والفوز في برنامج المسابقات التليفزيوني «المحك!» (جيبردي)، والمساعدة على تصميم جسر كيلا ينهار حال ارتطام شاحنة بأحد الأعمدة التي ترفعه، وتأليف موسيقى تروق للأذن إلى حد مدهش (وفي بعض الأحيان تكون جيدة حقا). أنظمة الذكاء الاصطناعي التي تدعى روبوتات الدردشة في وسعها إجراء محادثة معك. لا يمكن إنكار أن لهذه التكنولوجيا عيوبها، والمحادثات التي تجريها روبوتات الدردشة قد تكون غريبة حقا. فيما يلي نموذج لمحادثة بين إنسان وروبوت دردشة؛ لن تلقى صعوبة كبيرة في تمييز الإنسان عن نظام الذكاء الاصطناعي.(@)(@)(@@) جورج :(@)(@)(@@) مرحبا، اسمي جورج وأنا إنسان.(@)(@)(@@) جون :(@)(@)(@@) مرحبا أنا جون.(@)(@)(@@) جورج :(@)(@)(@@) من أي بلد أنت؟(@)(@)(@@) جون :(@)(@)(@@) أنا أعيش على جزيرة مارثاز فينيارد.(@)(@)(@@) جورج :(@)(@)(@@) سوف أذهب 
ms90	 إلى المريخ، وسوف أحطم وجهك بمضرب البيسبول!(@)(@)(@@) جون :(@)(@)(@@) حسنا ... هذا رد وقح بعض الشيء.(@)(@)(@@) جورج :(@)(@)(@@) أنا لست مثقوبا .(@)(@)(@@) جون :(@)(@)(@@) لست مثقوبا؟ تقصد مثقابا أو ما شابه؟ مثقاب الحفر؟(@)(@)(@@) جورج :(@)(@)(@@) بعض الشيء.(@)(@)(@@) جون :(@)(@)(@@) حسنا، من أي بلد أنت؟ وكم عمرك؟ ... إلخ.(@)(@)(@@) جورج :(@)(@)(@@) عمري 39.(@)(@)(@@) جون :(@)(@)(@@) وهل تقيم ...؟(@)(@)(@@) جورج :(@)(@)(@@) لا، أنا أعيش في هولندا.(@)(@)(@@) جون :(@)(@)(@@) في أي جزء منها؟ المدينة أم الريف؟ هل تزرع الأزهار أيضا؟(@)(@)(@@) جورج :(@)(@)(@@) أزرع الكثير من الأزهار. وسوف أزرع طماطم قريبا.(@)(@)(@@) جون :(@)(@)(@@) لقد تأخرت قليلا على موسم زراعة الطماطم.(@)(@)(@@) جورج :(@)(@)(@@) لا، حيوان قليل.(@)(@)(@@) جون :(@)(@)(@@) حسنا، فلنكتف بهذا الحديث الآن. سوف أذهب للتحدث مع روبوت آخر.(@)(@)(@@) جورج :(@)(@)(@@) حسنا إذن، شكرا على مشاركة فرشاة شعرك معي.(@)(@)(@@) جون :(@)(@)(@@) ماذا تقصد؟ كيف شاركتك فرشاة شعري؟(@)(@)(@@) جورج :(@)(@)(@@) جيد.(@)(@)(@@) جون :(@)(@)(@@) جيد؟(@)(@)(@@) جورج :(@)(@)(@@) نعم.(@)(@)(@@) جون :(@)(@)(@@) يا لها من محادثة عميقة!(@)(@)(@@) جورج :(@)(@)(@@) بل وأسوأ من ذلك، لقد تبرعت بها إلى جمعية خيرية.(@)(@)(@@) كان ذلك نص محادثة أجريت كجزء من مسابقة جائزة لوبنر عام 2005 لروبوتات الدردشة.(@)(@)(@@) 4(@)(@)(@@) وقد فاز جورج بها (بالطبع جورج هو البرنامج الحاسوبي، وليس جون)، وهو نسخة من برنامج ممتاز وفعال لروبوتات الدردشة يدعى «جابرواكي».(@)(@)(@@) تختبر المسابقة مهارة المحادثة عبر تشغيل نسخة مما يعرف باسم «اختبار تيورنج»؛ حيث يوضع الإنسان في مواجهة الآلة. في هذا الاختبار يجري أحد الأفراد حديثا مع إنسان ومع آلة حول أي موضوع يختاره، ويهدف الاختبار إلى اكتشاف أي من الطرفين اللذين تحدث معهما هو الآلة ومن هو الإنسان. إذا لم يستطع الفرد معرفة الفرق بينهما، تعتبر الآلة ذكية حقا. تطبق مسابقة جائزة لوبنر نسخة محدودة من اختبار تيورنج (حيث المحادثات أقصر كثيرا من تلك التي يتضمنها الاختبار الكامل). عجز جورج بالطبع عن اجتياز هذه النسخة المحدودة من الاختبار، لكن أداءه تفوق على البرامج الأخرى في المسابقة.(@)(@)(@@) ابتكر ألان تيورنج (1912-1954)، عالم الرياضيات العظيم ومؤسس علم الكمبيوتر، اختبار تيورنج عام 1950. اعتقد تيورنج أن الكفاءة التحاورية هي اختبار كاف لتحديد برنامج الذكاء الاصطناعي الناجح. لم يزعم أن كل آلة ذكية لا بد أن تكون 
ms91	 قادرة على إجراء محادثة جيدة - فهناك أوجه أخرى كثيرة للتمتع بالذكاء - لكنه زعم أن أي آلة تستطيع أن توهمنا بأننا نتحدث مع إنسان لا بد أن تكون آلة ذكية. إن الذكاء التحاوري نوع يحتاج لتلبية الكثير من المتطلبات؛ إذ يستلزم وجود قاعدة بيانات ضخمة من المعرفة السابقة، وقدرة على بحث هذه البيانات بسرعة الضوء، إلى جانب إتقان ضليع للغة البشر. علاوة على ذلك، هو يتطلب قدرة على متابعة الحديث عندما تتغير الموضوعات فجأة، والاحتفاظ بالمعلومات ذات الصلة (المعلومات ذات الصلة فحسب) طوال المحادثة، وإعداد ردود مناسبة ووثيقة الصلة بالموضوع وغيرها من المتطلبات. لم تستطع أي آلة حتى الآن الاقتراب من اجتياز اختبار تيورنج. إلا أن روبوتات الدردشة تتحسن كل عام.(@)(@)(@@) 5(@)(@)(@@) في فيلم سبيلبيرج، اجتياز اختبار تيورنج أمر في غاية السهولة. فحتى دمية الدب الخاصة بديفيد في وسعها اجتياز اختبار تيورنج. لكن ما الذي يقيسه اختبار تيورنج تحديدا؟ هو يقيس مستوى الكفاءة التحاورية؛ أي «السلوك» التحاوري. إنه لا يختبر الفهم التحاوري بالضرورة. لقد تمكن جورج من إجراء نسخة طبق الأصل مما نطلق عليه محادثة (وإن كانت تشبه محادثة مع شخص شبه مخبول)، لكن لا يمكن زعم أنه يفهم ما يتحدث عنه. فجورج يتبع القواعد ليس إلا. هو يبحث عن الكلمات في قاعدة البيانات لكنه لا يعرف ما الذي يشير إليه أي من المدخلات، ويعد ردودا، لكنه لا يعرف معناها. هل كان هذا سيتغير لو أصبح جورج، أو أحد أحفاده من روبوتات الدردشة، بارعا حقا في إعداد إجابات تجتاز اختبار تيورنج؟ من الصعب الإجابة عن سؤال كهذا. لقد ابتكر الفيلسوف الأمريكي جون سيرل تجربة افتراضية شهيرة جدا تهدف إلى حل هذه المسألة، يطلق عليها تجربة الغرفة الصينية (سيرل 1980-1984).(@)(@)(@@) الغرفة الصينية(@)(@)(@@) تخيل أنك استيقظت من نوم ناتج عن تأثير مخدر لتجد نفسك في غرفة. تحتوي الغرفة على خزانة ملفات عملاقة، وسلة مليئة بقوالب على شكل رموز غريبة، وطاولة وأقلام رصاص وورقة، وملف يحمل عنوان «تعليمات السيد». يوجد بالغرفة كذلك فتحتان لإدخال الأشياء وإخراجها 
ms92	 من الغرفة، مكتوب فوق إحداهما «مدخلات» وفوق الأخرى «مخرجات». تنزلق قوالب عبر فتحة المدخلات الواحدة تلو الأخرى، وهي في الظاهر أشبه برموز. في الوقع تشبه إلى حد ما الرموز الموجودة في السلة، وتبدو مثل شخبطات عشوائية (على حد وصف سيرل). بل هي فعليا تشبه إلى حد كبير حروف اللغة الصينية، وهي لغة سنفترض أنك لا تستطيع قراءتها. ما المطلوب منك فعله بهذه الرموز؟ ستلجأ، بعدما تصيح طلبا للمساعدة دون جدوى، إلى الحل البديهي؛ ألا وهو مراجعة ملف «تعليمات السيد». ستخبرك التعليمات بما عليك البدء بفعله، وهي لحسن الحظ مكتوبة بالإنجليزية. وعليه يتضح أن مهمتك هي تسجيل ترتيب وصول الرموز إلى الغرفة، ثم البحث عنها بنفس الترتيب في فهرست خزانة الملفات. يعقب ذلك مجموعات إضافية من التعليمات، وهي تعليمات معقدة تعقيدا رهيبا، لكنها مصاغة بلغة إنجليزية جيدة ومحددة للغاية، وتوضح لك ما عليك فعله بالضبط، وترتيب فعله. يخبرك البند الأخير من التعليمات بأن تختار رمزا محددا من السلة الموجودة بالغرفة، ثم تدفعه عبر فتحة المخرجات. وهكذا تتبع التعليمات يوما بعد يوم، بل وتصبح بارعا في اتباعها.(@)(@)(@@) تلك هي غرفة سيرل الصينية (غيرنا بعض التفاصيل الفرعية تيسيرا للعرض). لقد تخيل الكمبيوتر من الداخل. في هذه الغرفة، يتبع الفرد عملية حاسوبية لمعالجة الرموز، وذلك هو جل ما تفعله أجهزة الكمبيوتر على حد قول سيرل. ذلك حقا هو كل ما «تستطيع» فعله. تشبه الغرفة الصينية برنامج دردشة آليا فائق القدرات، خبيرا في إجراء محادثات باللغة الصينية؛ تمثل الرموز المدخلة أسئلة المحاور وتعليقاته، في حين تمثل الرموز المخرجة إجابات الغرفة الصينية. بالطبع تجرى العملية كلها بإيقاع في غاية البطء. لكن بصرف النظر عن ذلك، ينبهر متحدثو الصينية البارعون بالمهارات التحاورية للغرفة الصينية. هم يطرحون الأسئلة ويبدون الملاحظات بينما تولد أنت الإجابات داخل الغرفة. وهكذا تجتاز الغرفة الصينية اختبار تيورنج، أو كانت لتجتازه لو لم تضيع كل شيء بسبب بطئك الشديد. لكن سيرل لا يعتقد أن المشكلة تكمن في السرعة إطلاقا، بل ما يهم ملاحظته هو 
ms93	 أنك ستظل داخل الغرفة عاجزا عن فهم كلمة واحدة من المحادثات حتى لو اجتازت الغرفة الصينية اختبار تيورنج باللغة الصينية. أنت لا تعرف عما تدور ولا تدرك معناها، ومع ذلك تؤدي جميع العمليات التي يؤديها الكمبيوتر؛ أي تتعرف على الرموز عبر شكلها، وتتبع التعليمات الخاصة بكيفية التعامل معها. وهذا هو ما يفعله الكمبيوتر تحديدا. وعليه، إذا كنت لا تفهم محادثة الغرفة الصينية، فليس بوسع أي كمبيوتر إذن فهم محادثة. وبالطبع سيفهم الكمبيوتر أقل مما تفهمه، فأنت على الأقل تفهم التعليمات بما إنها مكتوبة بالإنجليزية وتتبعها عن قصد وتأمل، في حين يتبع الكمبيوتر التعليمات المعطاة له على نحو آلي أعمى، دون أي فهم على الإطلاق.(@)(@)(@@) ابتكر سيرل تجربة الغرفة الصينية سعيا لطرح تسوية حاسمة ونهائية لمسألة الذكاء الصناعي. واستنتج أنه ربما تستطيع أنظمة الذكاء الاصطناعي «محاكاة» الأفكار والمحادثات البشرية لكنها عاجزة عن «التفكير» أو «فهم» هذه المحادثات. بالطبع، لا تحل تجربة سيرل الافتراضية المسألة بأي حال؛ فالفلاسفة ليسوا سهلي الإقناع لهذه الدرجة.(@)(@)(@@) 6(@)(@)(@@) ومن ثم ظهرت ردود لا حصر لها على حجة سيرل؛(@)(@)(@@) 7(@)(@)(@@) سنستعرض سريعا ثلاثة منها؛ وهي «رد الروبوت» و«رد النظام» بالإضافة إلى ما سنطلق عليه «رد النظامين» (الرد الأخير في الواقع هو رد على رد. لكن لا داعي للفزع، لن تجده عصيا على الفهم).(@)(@)(@@) رد الروبوت(@)(@)(@@) هذا الرد على حجة سيرل هو في الحقيقة نوع من التسليم المخادع بها؛ فنحن نسلم بأن الغرفة الصينية لا تفهم شيئا لكن نزعم أن اللوم في ذلك لا يرجع إلى مجرد كونها تشغل برنامجا حاسوبيا، بل يرجع إلى أن البرنامج قابع فحسب داخل الغرفة. إن الغرفة الصينية التي يتخيلها سيرل لا تملك ما يكافئ الرجلين واليدين والعينين والأذنين؛ فإذا طرق أحدهم بابها فلن تتمكن من معرفة هويته، وعليها الاعتماد على رموز غامضة تصل إليها عبر فتحة المدخلات. قد تنقل هذه الرموز معلومات حول الشخص الواقف عند الباب، لكن الغرفة الصينية لا تتفاعل مباشرة مع هذا الشخص؛ هي منعزلة عن بيئتها. جملة القول: الغرفة 
ms94	 الصينية ليست روبوتا، ربما كانت ستصبح أفضل حالا لو كانت كذلك. في فيلم سبيلبيرج، يتجلى فهم ديفيد وذكاؤه في الأساس من خلال تفاعله مع بيئته وتصرفاته اليومية، إلى جانب تنفيذه لخططه واستراتيجيته الطويلة الأمد كما في محاولته تحقيق حلمه بالتحول إلى صبي حقيقي. إن قدرة ديفيد على إجراء المحادثات تثير الإعجاب، لكننا واثقون على ما يبدو في أنه يعرف ما يتحدث عنه نظرا للطريقة التي يتفاعل بها مع بيئته. نحن متأكدون من أن ديفيد يعرف جزئيا معنى كلمة «تيدي» (اسم دميته) لأنه يستطيع مناداته ثم مطاردته وحمله.(@)(@)(@@) إذن، رجوعا إلى قصة سيرل، دعونا نتخيل غرفة صينية داخل روبوت. تخيل أنك محشور في مركز التحكم داخله حيث تؤدي جميع العمليات الحاسوبية اللازمة لعمل الروبوت. بما أن الروبوت يتفاعل مع بيئته؛ فقد يستطيع فهم الأفكار المتعلقة بتلك البيئة، وربما يتمكن من معرفة هوية الواقف عند الباب لأنه قادر على رؤيته؛ إذن تكمن مشكلة تجربة سيرل الافتراضية في أن الغرفة الصينية الأصلية ليست مجهزة على النحو الذي يمكنها من فهم الأشياء فهما حقيقيا. يتطلب الفهم من المرء تفاعلا سببيا مع بيئته، في حين لا يتاح للغرفة الصينية سوى تفاعل لفظي مع متحدثي اللغة الصينية الذين يلقمونها ملاحظات تحاورية مكتوبة. تفتقد الغرفة الصينية الخلفية التفاعلية السببية اللازمة لفهم أي من تلك الملاحظات. ذلك رد الروبوت على حجة سيرل، وهو رد له بعض المزايا؛ ففي النهاية ديفيد ليس غرفة صينية، وقد يستطيع فهم ما يحدث له لأنه روبوت وليس برنامج دردشة آليا.(@)(@)(@@) لكن لدى سيرل ردا مقنعا على ذلك؛ فلنفترض أننا حولنا الغرفة الصينية إلى روبوت، ثم وضعناك داخل مركز التحكم؛ وبذلك نكون وهبنا روبوت الغرفة الصينية هذا ملكة الإدراك؛ إذ يصبح قادرا على أن يرى ويسمع ويلمس ما يحيط به. لكن هذا لا يعني أنك - الشخص القابع بداخله - تستطيع ذلك أيضا. وتثبيت كاميرا على الروبوت من الخارج كي تنقل لك في غرفة التحكم صورا للعالم الخارجي لن يحل المشكلة؛ فماذا ستستطيع فعله بتلك الصور 
ms95	؟ نحن لا ندرك العالم لأن شخصا صغير الحجم يجلس داخل رأسنا يشاهد التليفزيون، وينطبق ذلك على الروبوت، وعلى روبوت الغرفة الصينية كذلك.(@)(@)(@@) 8(@)(@)(@@) ستدخل الصور غرفة التحكم كمعلومات، وهذه المعلومات لا بد أن تقدم في صورة تتيح لك اتباع القواعد التي توضح لك ما عليك فعله بها، وهنا تكمن المشكلة؛ إذا دخلت المعلومات الغرفة بهذه الطريقة، فلا يوجد ما يضمن أنك ستستطيع فك شفرتها؛ فربما تبدو لك أشبه بالمزيد من الشخبطات العشوائية غير المفسرة وحسب. لن يمنعك ذلك من تمييز الأنواع المختلفة من الشخبطات؛ فلديك القدرة على تحديد الشكل المميز لكل نوع من الشخبطات والتعرف عليه مجددا كلما ظهر، ويمكنك فعل ذلك دون معرفة ما ترمز إليه هذه الشخبطات. يطلق الفلاسفة على هذا النوع من التركيب المعلوماتي اسم «تركيب نحوي». يشير سيرل إلى أن المعلومات ستصل إلى مركز تحكم داخل الروبوت في شكل تراكيب نحوية غير مفسرة. وبفضل القواعد المحفوظة في خزانة الملفات، يعرف الجالس في غرفة التحكم ما عليه فعله بالمعلومات ذات التركيب النحوي، لكنه لن يعرف كيف يفسر هذا التركيب. بعبارة أخرى: لن يعرف معنى أي من تلك التراكيب. وبهذه الطريقة، يمكننا بسهولة تخيل (حسنا، يمكننا أن نتخيل) روبوت غرفة صينية يقوم بمهامه الآلية بينما تجلس أنت في غرفة التحكم لأجل العمل على تيسير تلك المهام، وتظل مع ذلك لا تفقه شيئا.(@)(@)(@@) يبدو سيرل محقا؛ تحويل الغرفة الصينية إلى روبوت يحوي غرفة صينية لن يتيح لنا تفنيد حجته. بالطبع قد تساعدنا الفكرة الأصلية رغم ذلك على تفنيدها؛ فالفكرة القائلة بأن التفاعل البيئي لا غنى عنه إذا أردنا لنظام ذكاء اصطناعي اكتساب الفهم، هي فكرة منطقية للغاية. والزعم الذي نطرحه ها هنا، نيابة عن سيرل، هو أن مجرد إضافة وظائف الروبوت إلى الغرفة الصينية لن يتيح للجالس في غرفة التحكم فهم ما يفعله الروبوت. إذا كانت حجة الغرفة الصينية الأصلية صحيحة، فإن حجة روبوت الغرفة الصينية ستكون صحيحة كذلك.(@)(@)(@@) رد النظام(@)(@)(@@) لن يفي رد الروبوت بالغرض، لكن يوجد رد أفضل 
ms96	 في المتناول؛ تخيل أنك عالق داخل الغرفة الصينية (أو في مركز التحكم الخاص بروبوت الغرفة الصينية)، عاجز عن فهم ما يفعله النظام كله. وهو أمر لا يستدعي الدهشة؛ فأنت لست الغرفة الصينية ذاتها، بل أنت البرنامج الذي ينفذ أوامر النظام. بعبارة أخرى: أنت من يتولى المهام الروتينية ويتبع التعليمات دون تفكير. وتشبه في ذلك وحدة المعالجة المركزية داخل جهاز الكمبيوتر العادي. يتكون جهاز الكمبيوتر من أجزاء أخرى كثيرة بجانب وحدة المعالجة المركزية؛ يحتوي النظام بأكمله على قرص صلب، وذاكرة عشوائية، وذاكرة مؤقتة، وبطاقة عرض مرئي، ونظام تشغيل، وبرامج تشغيل، ووحدات طرفية من شتى الأنواع ... إلخ. إذا كنت تلعب دور وحدة المعالجة المركزية الخاصة بالغرفة الصينية، فأنت إذن لست الغرفة الصينية ذاتها، بل لست الجزء الأهم من الغرفة الصينية. في وسعنا إخراجك منها ووضع شخص آخر مكانك، ولن يلاحظ النظام أي تغيير على الإطلاق، ما دام بديلك قادرا على اتباع التعليمات مثلما كنت تتبعها. وبما أنك مجرد جزء صغير قابل للاستبدال من الغرفة الصينية، لن يدهشنا عجزك عن فهم ما يفعله النظام بأكمله. إذا كان هناك من يفهم اللغة الصينية في هذه التجربة الافتراضية، فهو النظام المتكامل. وأنت لست هذا النظام. هذا هو رد النظام على حجة سيرل.(@)(@)(@@) لكن سيرل لا يزال بعيدا عن الاقتناع، فكيف يمكن عبر إضافة بعض قطع الأثاث (مثل خزانة الملفات، والسلة التي تحوي رموزا عشوائية، وغير ذلك) تحويل شيء عاجز عن الفهم (وهو أنت في هذه الحالة) إلى شيء قادر على الفهم (أي نظام الغرفة الصينية)؟ قد نندفع قائلين: «هذا هو ما يحدث وحسب.» خزانة الملفات عاجزة وحدها عن الفهم؛ فهي ليست سوى مجموعة من المعلومات الجامدة. وأنت أيضا عاجز عن الفهم؛ فلست سوى تابع أعمى للتعليمات. لكن إذا جمعنا الاثنين معا فقد نحصل على كيان أكبر من حاصل مكوناته. سنحصل على نظام معالجة معلومات نشط وفعال، وسيرل لم يقدم لنا ما يثبت أن نظاما كهذا عاجز عن فهم اللغة الصينية.(@)(@)(@@) يحاول سيرل مجددا تفنيد هذا 
ms97	 الرد أيضا؛ تخيل أنك في الغرفة الصينية منذ أمد طويل جدا حتى أصبحت مطلعا تماما على التعليمات في خزانة الملفات، وتخيل أنك تتمتع بذاكرة مذهلة مكنتك في النهاية من حفظ التعليمات كلها عن ظهر قلب، والآن عندما يصل قالب من الشخبطات العشوائية إلى الغرفة عبر فتحة المدخلات، لن تحتاج إلى الاطلاع على التعليمات في خزانة الملفات كي تعرف ما عليك فعله به، بل ستكتفي فحسب بالرجوع إلى ذاكرتك. يزعم سيرل أن في هذه التجربة الافتراضية الجديدة يتحول الشخص الجالس في الغرفة إلى نظام الغرفة الصينية ذاته لا مجرد وحدة المعالجة المركزية الغبية داخله. ورغم ذلك لن تعرف عم يتحدث نظام الغرفة الصينية، وسيظل الكلام مجرد شخبطات عشوائية بالنسبة إليك. يبين لك هذا أن نظام الغرفة الصينية عاجز عن فهم ما يتحدث عنه. لقد أصبحت أنت النظام الآن، لقد احتويت النظام بأكمله داخل ذاكرتك، ورغم ذلك ما زلت لا تفهم. كيف إذن يستطيع الكمبيوتر الفهم بأي حال؟(@)(@)(@@) رد النظامين(@)(@)(@@) لقد شرحنا لتونا ردا على حجة سيرل (رد النظام) ورد سيرل على هذا الرد. والآن حان الوقت لطرح ردنا الأخير (في الوقت الحالي على الأقل)، ألا وهو رد النظامين. يطلب منك سيرل أن تتخيل نفسك تحفظ قائمة تعليمات الغرفة الصينية بأكملها عن ظهر قلب. يبدو ذلك إنجازا عصيا على التصديق، لكن التجارب الافتراضية الفلسفية تسمح بما لا يصدق. دعونا نطلق على هذا الشخص ذي الذاكرة المذهلة اسم «ذو الرأس الكبير». في الظاهر ذو الرأس الكبير هو أنت بعدما اكتسبت قدرا من الذاكرة الإضافية. لكن المظاهر خداعة؛ فقد لا يبدو حفظ برنامج الغرفة الصينية في الذاكرة أمرا يختلف كثيرا عن حفظ أي شيء آخر، مثل جدول مواعيد قطارات أمريكا الشمالية مثلا، لكنه في الحقيقة في غاية الاختلاف. يختلف لأن ذا الرأس الكبير يستخدم تذكره لبرنامج الغرفة الصينية بطريقة خاصة جدا. عندما تتذكر جدول مواعيد القطارات كي تلحق بقطار ما، فإنك تخلق روابط بين الجدول وبين باقي ما تملكه من معرفة. أنت تعرف كيف 
ms98	 تحدد الوقت وتعرف كم تبقى من الوقت على حلول الساعة الواحدة مساء. أنت تعرف أن الوصول في الساعة الثانية مساء من أجل اللحاق بقطار سيغادر في الواحدة مساء يعني أنك تأخرت على الأرجح على موعد القطار ... إلخ، لكن عندما يحفظ ذو الرأس الكبير تعليمات الغرفة الصينية في الذاكرة، لا يحدث هذا النوع من الاندماج المعرفي؛ فالجزء الخاص بالغرفة الصينية لدى ذي الرأس الكبير لا يندمج مع باقي أجزاء النظام المعرفي لديه اندماجا كاملا، بل لا يكاد يندمج على الإطلاق.(@)(@)(@@) يتألف ذو الرأس الكبير فيما يبدو من نظامين معرفين: الأول هو النظام العادي الخاص بك؛ أي النظام الذي يمكنك من اللحاق بالقطارات في موعدها. والثاني هو نظام الغرفة الصينية؛ أي النظام الذي يتيح لذي الرأس الكبير التحاور مع متحدثي اللغة الصينية. بالطبع ستمر بوقت عصيب وأنت تحاول التوحد مع مكون الغرفة الصينية لدى ذي الرأس الكبير. سيظل هذا المكون غامضا بالنسبة إليك لأنه لا يندمج كما ينبغي مع باقي مكونات عقلك. أنت لا تفهم ما يفعله هذا الجزء. لكن هذا يعني ببساطة أنك لست ذا الرأس الكبير. يتألف ذو الرأس الكبير من نظامين، وأنت نظام واحد منهما فحسب. النظامان مرتبطان، لكن بطريقة غريبة بعض الشيء. يلعب نظامك دور البرنامج المنفذ لنظام الغرفة الصينية، وبدون تدخلك الرامي لاتباع المعلومات، كان نظام الغرفة الصينية سيظل قابعا في داخل ذاكرة ذي الرأس الكبير دون أن يقدر على تحقيق أي شيء.(@)(@)(@@) والآن نطرح السؤال التالي: هل يفهم ذو الرأس الكبير اللغة الصينية؟ «أنت» لا تفهم اللغة الصينية، لكنك لست ذا الرأس الكبير؛ فهل يفهم ذو الرأس الكبير اللغة الصينية؟ من الصعب الإجابة عن ذلك. ما لا نستطيع قوله هو ما كان سيرل سيريد منا قوله، ومفاده أن ذا الرأس الكبير لا يفهم اللغة الصينية لأنك أنت لا تفهم الصينية. فهذه حجة غير سليمة لأنها تفترض كذبا أنك أنت وذا الرأس الكبير تشكلان نظاما معرفيا واحدا. هذا ليس صحيحا. إن نظام الغرفة الصينية داخل ذي الرأس 
ms99	 الكبير يشبه غزوا أجنبيا لعقلك؛ فهو قابع في ذاكرتك مثل فيروس، مستغلا عادتك في اتباع التعليمات.(@)(@)(@@) وهكذا أخفقت حجة الغرفة الصينية التي طرحها سيرل؛ ففي النهاية، هو لا يملك ردا مقنعا على رد النظامين. لكن هذا لا يعني أن استنتاجه خاطئ؛ فعبر تفنيد حجة سيرل لا نثبت أن الغرفة الصينية تفهم بالفعل اللغة الصينية، بل نثبت فحسب أننا لا نستطيع استخدام حجة سيرل لإثبات أنها لا تفهم اللغة الصينية. بالطبع ذو الرأس الكبير كائن غريب جدا، ولدينا من المبررات المقنعة ما يدفعنا إلى الشك في أن مكون الغرفة الصينية داخله يفهم شيئا حقا. وبما أنه لا يندمج كما ينبغي في نظامك المعرفي، فإنه لا يتمتع بنفس كفاءتك الآلية. وبدون الكفاءة الآلية؛ أي بدون الانغماس السببي المتعمق في بيئته، من غير المرجح على الإطلاق أن يفهم محتوى محادثاته مع المتحدثين باللغة الصينية. إن علينا الجمع بين رد الروبوت ورد النظام كي نجعل فكرة نظام الذكاء الاصطناعي الذي يفهم ما يفعله منطقية.(@)(@)(@@) يعيدنا ذلك إلى فيلمنا. ليس من قبيل المصادفة أن يجسد الخيال العلمي أنظمة الذكاء الاصطناعي عادة في شكل روبوت؛ فحتى أجهزة الكمبيوتر التي تفتقد مجموعة مهارات الروبوت الكاملة، مثل الكمبيوتر هال في فيلم «2001: ملحمة الفضاء» (1968)، لديها مخزون ذاخر من القدرات الإدراكية الحسية والتنفيذية؛ فلدى هال على سبيل المثال أعين وآذان في كل مكان، وهو قادر على فتح أبواب المكوك الفضائي أو عدم فتحها وقتما يريد. في فيلم «ذكاء اصطناعي» ترتبط قدرات ديفيد الإدراكية ارتباطا وثيقا بأدائه الوظيفي كروبوت؛ فهو يتعلم عبر مشاهدة الآخرين ومحاكاتهم (ليس محاكاتهم حرفيا؛ فعندما يحاول بلع الطعام في مشهد تناول العشاء يكاد فكه ينفصل عن وجهه). ربما ديفيد قادر فعليا على الفهم جزئيا بسبب هذا الأداء الوظيفي. ربما يفهم حقا معنى «خصلة شعر» لأنه يستطيع قص خصلة من شعر مونيكا والتحدث عنها فيما بعد. ربما لديه فكرة ما عن طبيعة الجنية الزرقاء؛ لأنه قادر على الذهاب بحثا عنها.(@)(@)(@@) هل ديفيد قادر على الشعور؟ اعتراض الكيفيات المحسوسة 
ms100	(@)(@)(@@) بماذا سنشعر يا ترى لو كنا مثل ديفيد؟ لا يمكننا وضع أنفسنا داخل عالمه العقلي عبر تخيل نسخة تشبهه من تجربة الغرفة الصينية الافتراضية؛ فكما رأينا، أخفقت هذه التجربة في تحقيق هدفها. لكن هناك سبب آخر يدفعنا إلى التشكك في قدرات ديفيد العقلية؛ فلماذا نفترض أنه «يشعر» حقا بأي شيء؟ هو يسجل التجارب في صورة تدفق معلوماتي داخل نظام معرفي، لكن هل هو واع كليا؟ وهل يمكن من الأساس طرح سؤال عما سنشعر به لو كنا مكانه؟ هل يشعر ب «الألم» عندما تهجره أمه في الغابة؟ هو يتصرف كما لو كان متألما، لكن هل يشعره الهجر بالألم حقا؟(@)(@)(@@) قد نتخيل أن ديفيد يبدي ردود أفعال تمثيلية مقنعة تعكس الألم والكرب دون أن يشعر فعليا بأي ألم أو كرب. نحن نعرف كيف يكون الشعور بالألم، وكيف يكون التظاهر بالشعور بالألم. لكن كيف نستطيع تحديد الفرق ظاهريا؟ يطلق الفلاسفة على الصفة الواعية لأي خبرة - أي «التألم» المميز للألم، أو «الحمرة» المميزة للون الأحمر، أو «النشاز» الذي يميز مجموعة نغمات موسيقية متنافرة - كيفية محسوسة، وجمعها كيفيات محسوسة. ومن هنا ينبع اعتراض آخر على أصالة ديفيد. هو لا يستطيع أن يحب مونيكا حبا حقيقيا؛ لأنه صمم كي يتصرف كما لو أنه يحظى بخبرات غنية بالكيفيات المحسوسة، بينما هو في الواقع لا يملك هذه الخبرات. عندما يشعر بالحزن على ما يبدو عند معرفته أن مونيكا يوما ما ستموت، فإنه لا يفعل أكثر من مجرد محاكاة السلوك المنتظر منه في هذه الحالة. إنه لا يشعر في الحقيقة بأي اغتمام فعلي، رغم تصورنا أنه من المستحيل تماما الجزم بأنه لا يشعر بذلك. يفتقد ديفيد الكيفية الحسية الخاصة بالشعور بالكرب أو الاغتمام. لا يمكننا معرفة ما الذي سنشعر به لو كنا مكان ديفيد بينما يبدو مغتما، بل لا يمكننا معرفة ما سنشعر به لو كنا مكان ديفيد من الأساس؛ فذلك يشبه تخيل ما سنشعر به لو كنا محمصة خبز مثلا. هذا ما يطلق عليه اعتراض الكيفيات المحسوسة.(@)(@)(@@) حتى 